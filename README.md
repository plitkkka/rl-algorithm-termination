**Reinforcement Learning Algorithm Termination**

Алгоритмы выполнения обучения с подкреплением SARSA и Q-learning. Обучение проводится на лабиринте, который считывается из файла.


> Описание предметной области

Лабиринт представляет собой матрицу, которая представляет вознаграждения, которые агент получает при посещении каждой клетки. Большое отрицательное вознаграждение соответствуют препятствиям (стенкам) лабиринта. 
Большое положительное вознаграждение соответствует выходу из лабиринта.

Обучение с подкреплением (англ. reinforcement learning) — один из способов машинного обучения, в ходе которого испытуемая система (агент) обучается, взаимодействуя с некоторой средой. 
С точки зрения кибернетики, является одним из видов кибернетического эксперимента. Откликом среды (а не специальной системы управления подкреплением, как это происходит в обучении с учителем) на принятые решения являются сигналы подкрепления, 
поэтому такое обучение является частным случаем обучения с учителем, но учителем является среда или её модель. 
Некоторые правила подкрепления базируются на неявных учителях, например, в случае искусственной нейронной среды, на одновременной активности формальных нейронов, из-за чего их можно отнести к обучению без учителя.
Агент воздействует на среду, а среда воздействует на агента (см. рис. 1). О такой системе говорят, что она имеет обратную связь. Такую систему нужно рассматривать как единое целое, и поэтому линия раздела между средой и агентом достаточно условна. 
Конечно, с анатомической или физической точек зрения между средой и агентом (организмом) существует вполне определённая граница, но если эту систему рассматривать с функциональной точки зрения, то разделение становится нечётким. 
Например, резец в руке скульптора можно считать либо частью сложного биофизического механизма, придающего форму куску мрамора, либо частью материала, которым пытается управлять нервная система.

![image](https://github.com/user-attachments/assets/a33fee30-d0fe-40aa-8133-f4ab4d1ce3a2)

Рис. 1 – Воздействие системы « Агент – Среда»

> Тестирование

1)	Матрица лабиринта (см. рис 2)

 ![image](https://github.com/user-attachments/assets/2c84946a-c468-4dc4-a554-8d0f86d7af09)

Рис. 2 – Матрица лабиринта

2)	Генерация исходного лабиринта (см. рис.3)

 ![image](https://github.com/user-attachments/assets/e44d1207-54c5-40f4-9370-163621c39bf7)

Рис. 3 – Сгенерированный лабиринт

3)	Реализация алгоритма (см. рис. 4)

 ![image](https://github.com/user-attachments/assets/c32e91ae-7531-4010-a49c-c73b1e6df552)

Рис. 4– Путь прохождения лабиринта

4)	Реализация награды агента (см. рис. 5)

![image](https://github.com/user-attachments/assets/149acc97-b434-4346-8329-2acfee6eb06f)
